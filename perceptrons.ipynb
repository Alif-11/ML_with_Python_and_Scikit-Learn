{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neurons: \n",
    "Uses a decision function, sigma of (z), to determine whether the input z belongs in class 0 or 1.\n",
    "\n",
    "z is actually defined as a dot product between a weights vector, W, and a inputs vector, X. \n",
    "\n",
    "If z is bigger than some threshold value T, then z is classified as class 0. Otherwise, z is classified into class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuron output on (-2,2): 0\n"
     ]
    }
   ],
   "source": [
    "# Simple Implementation\n",
    "\n",
    "class ArtificialNeuron:\n",
    "  \"\"\"\n",
    "  All matrices/vectors that interact with this class must be a numpy array.\n",
    "  \n",
    "  Implementation of an artificial neuron\n",
    "  \"\"\"\n",
    "  def __init__(self, W, T):\n",
    "    self.weights = W\n",
    "    self.threshold = T\n",
    "  \n",
    "  def __init__(self, num, T):\n",
    "    self.weights = np.random.rand(num)\n",
    "    self.threshold = T\n",
    "  \n",
    "  def classify(self, inputs):\n",
    "    \"\"\"\n",
    "    Returns if the dot product between the weights and the inputs is greater than the threshold value.\n",
    "    \"\"\"\n",
    "    assert inputs.shape == self.weights.shape, \"Inputs does not match weights shape\"\n",
    "    z = np.dot(self.weights, inputs)\n",
    "    if z >= self.threshold:\n",
    "      return 1\n",
    "    else:\n",
    "      return 0\n",
    "\n",
    "# Testing our code out\n",
    "neuron = ArtificialNeuron(np.array(2), 0.8)\n",
    "print(\"neuron output on (-2,2):\", neuron.classify(np.array([-2,2])))\n",
    "    \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development of the Perceptron\n",
    "Note that, if we were to take the threshold value and subtract it from the dot product between the weights and the input vector, we could then simply see if the difference is greater than 0.\n",
    "\n",
    "This idea leads to the concept of biases, and ultimately lands us in Perceptron land. Take a look at my implementation of the Perceptron, heavily derived from the Artificial Neuron class.\n",
    "\n",
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Implementation\n",
    "\n",
    "class Perceptron:\n",
    "  \"\"\"\n",
    "  All matrices/vectors that interact with this class must be a numpy array.\n",
    "  \n",
    "  Implementation of the Perceptron Algorithm\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, num, alpha):\n",
    "    \"\"\"Randomly initializes weights and sets bias to 0. You must specify the \n",
    "    size of the weights vector (which should match the size of each training \n",
    "    sample). You also must choose the learning rate\"\"\"\n",
    "    self.weights = np.random.rand(num)\n",
    "    self.bias = 0\n",
    "    self.learning_rate = alpha\n",
    "  \n",
    "  def classify(self, inputs):\n",
    "    \"\"\"\n",
    "    Returns if the dot product between the weights and the inputs is greater than the threshold value.\n",
    "    \"\"\"\n",
    "    assert inputs.shape == self.weights.shape, \"Inputs does not match weights shape\"\n",
    "    z = np.dot(self.weights, inputs)\n",
    "    if z + self.b >= 0:\n",
    "      return 1\n",
    "    else:\n",
    "      return 0\n",
    "  \n",
    "  def train(self, training_set, epochs):\n",
    "    \"\"\"\n",
    "    This method expects n individual training data samples, and uses them\n",
    "    to perform weight and bias updates. \n",
    "\n",
    "    The shape of each individual sample in the training dataset should match \n",
    "    the shape of our weights vector.\n",
    "\n",
    "    The training_set should be a list of tuples, where index 0 of each tuple\n",
    "    is an input value, and index 1 is the correct label. \n",
    "    \"\"\"\n",
    "    \n",
    "    # for-loop implementation\n",
    "    for _ in epochs:\n",
    "      for individual_sample in training_set:\n",
    "        input_value, true_label = individual_sample\n",
    "        perceptron_output = np.dot(self.weights, input_value) + self.bias\n",
    "        predicted_label = None\n",
    "        if perceptron_output >= 0:\n",
    "          predicted_label = 1\n",
    "        else:\n",
    "          predicted_label = 0\n",
    "        \n",
    "        learning_rate_times_label_delta = self.learning_rate * (true_label - predicted_label)\n",
    "        weight_update = learning_rate_times_label_delta * input_value\n",
    "        bias_update = learning_rate_times_label_delta\n",
    "\n",
    "        self.weights = self.weights + weight_update\n",
    "        self.bias = self.bias + bias_update\n",
    "    \n",
    "  def get_weights_and_bias(self):\n",
    "    \"\"\"Returns weights and bias as a tuple\"\"\"\n",
    "    return (self.weights, self.bias)\n",
    "    \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.80210854, 0.51744301]), 0)\n"
     ]
    }
   ],
   "source": [
    "# Testing our perceptron algorithm implementation\n",
    "perceptron = Perceptron(2,0.01)\n",
    "print(perceptron.get_weights_and_bias())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing our data\n",
    "Let's now take the time to process our dataset. We are using the iris dataset. \n",
    "I have listed the file, iris.data, in datasets folder.\n",
    "\n",
    "### DATASET PROCESSING STILL IN DEVELOPMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined [[5.1 3.5 0]\n",
      " [4.9 3.0 0]\n",
      " [4.7 3.2 0]\n",
      " [4.6 3.1 0]\n",
      " [5.0 3.6 0]\n",
      " [5.4 3.9 0]\n",
      " [4.6 3.4 0]\n",
      " [5.0 3.4 0]\n",
      " [4.4 2.9 0]\n",
      " [4.9 3.1 0]\n",
      " [5.4 3.7 0]\n",
      " [4.8 3.4 0]\n",
      " [4.8 3.0 0]\n",
      " [4.3 3.0 0]\n",
      " [5.8 4.0 0]\n",
      " [5.7 4.4 0]\n",
      " [5.4 3.9 0]\n",
      " [5.1 3.5 0]\n",
      " [5.7 3.8 0]\n",
      " [5.1 3.8 0]\n",
      " [5.4 3.4 0]\n",
      " [5.1 3.7 0]\n",
      " [4.6 3.6 0]\n",
      " [5.1 3.3 0]\n",
      " [4.8 3.4 0]\n",
      " [5.0 3.0 0]\n",
      " [5.0 3.4 0]\n",
      " [5.2 3.5 0]\n",
      " [5.2 3.4 0]\n",
      " [4.7 3.2 0]\n",
      " [4.8 3.1 0]\n",
      " [5.4 3.4 0]\n",
      " [5.2 4.1 0]\n",
      " [5.5 4.2 0]\n",
      " [4.9 3.1 0]\n",
      " [5.0 3.2 0]\n",
      " [5.5 3.5 0]\n",
      " [4.9 3.1 0]\n",
      " [4.4 3.0 0]\n",
      " [5.1 3.4 0]\n",
      " [5.0 3.5 0]\n",
      " [4.5 2.3 0]\n",
      " [4.4 3.2 0]\n",
      " [5.0 3.5 0]\n",
      " [5.1 3.8 0]\n",
      " [4.8 3.0 0]\n",
      " [5.1 3.8 0]\n",
      " [4.6 3.2 0]\n",
      " [5.3 3.7 0]\n",
      " [5.0 3.3 0]\n",
      " [6.3 3.3 1]\n",
      " [5.8 2.7 1]\n",
      " [7.1 3.0 1]\n",
      " [6.3 2.9 1]\n",
      " [6.5 3.0 1]\n",
      " [7.6 3.0 1]\n",
      " [4.9 2.5 1]\n",
      " [7.3 2.9 1]\n",
      " [6.7 2.5 1]\n",
      " [7.2 3.6 1]\n",
      " [6.5 3.2 1]\n",
      " [6.4 2.7 1]\n",
      " [6.8 3.0 1]\n",
      " [5.7 2.5 1]\n",
      " [5.8 2.8 1]\n",
      " [6.4 3.2 1]\n",
      " [6.5 3.0 1]\n",
      " [7.7 3.8 1]\n",
      " [7.7 2.6 1]\n",
      " [6.0 2.2 1]\n",
      " [6.9 3.2 1]\n",
      " [5.6 2.8 1]\n",
      " [7.7 2.8 1]\n",
      " [6.3 2.7 1]\n",
      " [6.7 3.3 1]\n",
      " [7.2 3.2 1]\n",
      " [6.2 2.8 1]\n",
      " [6.1 3.0 1]\n",
      " [6.4 2.8 1]\n",
      " [7.2 3.0 1]\n",
      " [7.4 2.8 1]\n",
      " [7.9 3.8 1]\n",
      " [6.4 2.8 1]\n",
      " [6.3 2.8 1]\n",
      " [6.1 2.6 1]\n",
      " [7.7 3.0 1]\n",
      " [6.3 3.4 1]\n",
      " [6.4 3.1 1]\n",
      " [6.0 3.0 1]\n",
      " [6.9 3.1 1]\n",
      " [6.7 3.1 1]\n",
      " [6.9 3.1 1]\n",
      " [5.8 2.7 1]\n",
      " [6.8 3.2 1]\n",
      " [6.7 3.3 1]\n",
      " [6.7 3.0 1]\n",
      " [6.3 2.5 1]\n",
      " [6.5 3.0 1]\n",
      " [6.2 3.4 1]\n",
      " [5.9 3.0 1]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/iris.data\",header=None)\n",
    "setosa = df.iloc[0:50, [0,1,4]].values # get sepal length and width of setosa\n",
    "virginica = df.iloc[100:, [0,1,4]].values # get sepal length and width of virginica\n",
    "combined_set_no_label_conversion = np.concatenate((setosa,virginica))\n",
    "combined_set_no_label_conversion[combined_set_no_label_conversion[:,2]==\"Iris-setosa\",2] = 0\n",
    "combined_set_no_label_conversion[combined_set_no_label_conversion[:,2]==\"Iris-virginica\",2] = 1\n",
    "print(\"combined\", combined_set_no_label_conversion)\n",
    "#print(\"setosa\", setosa)\n",
    "#print(\"virginica\", virginica)\n",
    "combined_set = combined_set_no_label_conversion\n",
    "y = combined_set[:,2]\n",
    "X = combined_set[:,[0,1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
